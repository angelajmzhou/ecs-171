{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329de2fb",
   "metadata": {},
   "source": [
    "#### Homework3\n",
    "Please explain clearly and include your entire computational work when needed. Should you include any code, please make sure to provide additional comments to explain your solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037db7a3",
   "metadata": {},
   "source": [
    "Q1 (30 points) Hyper-parameter Tuning: Provide your coding for this exercise. Your code should run without error and the output should be correct based on your assumptions. \n",
    "---\n",
    "- Create a dummy dataset with 3 input features (X) and a numeric output variable (y). Your daatset should have 300 data points. The train:test split is 75:25. \n",
    "- Standardize the input features. \n",
    "- Construct a 3-layer neural network with 2 neurons in the hidden layer and one neuron in the output layer. Use Relu as the activation function in the hidden layer. Use Sigmoid as the activation function in the output layer. \n",
    "- At this step, you are to use grid search to perform hyper-parameter tuning based on regularization and regularization parameter, momentum term, and batch size. For each paramter, try 2 different values. Refer to \"lec11-grid-search.ipynb\" as a reference. You are not allowed to copy-paste the code to solve this assignment. Just use it to learn what to do. Use SGD as your optimization technique. \n",
    "- In your code, report which subset of hyper-parameters give the best model. Then using the best hyper-parameters that you reported, visualize the MSE loss on train and test data over multiple epochs (the number of epochs depends on model convergence). \n",
    "\n",
    "Note: Hyperparameter tuning takes a lot of time to execute. Make sure that you choose the appropriate number of each hyperparameter (preferably 3 of each), and that you allocate enough time to execute your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1ec89-64cc-4d1a-bdbf-da2239b93460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "# Step 1: Create a dummy dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(300, 3)  # 300 data points with 3 features\n",
    "y = np.random.rand(300, 1)  # Numeric output variable\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Define a function to build the neural network model\n",
    "def build_model(reg_param, momentum):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_param)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(momentum=momentum)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Define hyperparameter grid\n",
    "reg_params = [0.01, 0.001]\n",
    "momentums = [0.8, 0.9]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "# Step 4: Grid search for hyperparameter tuning\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "results = []\n",
    "\n",
    "for reg_param, momentum, batch_size in product(reg_params, momentums, batch_sizes):\n",
    "    # Build and train the model\n",
    "    model = build_model(reg_param, momentum)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    # Evaluate the model\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "    results.append((reg_param, momentum, batch_size, loss))\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_params = (reg_param, momentum, batch_size)\n",
    "        best_model = model\n",
    "\n",
    "# Step 5: Report best hyperparameters and visualize training process\n",
    "reg_param, momentum, batch_size = best_params\n",
    "history = best_model.history.history\n",
    "\n",
    "# Plot the MSE loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history['mse'], label='Train MSE')\n",
    "plt.plot(history['val_mse'], label='Test MSE')\n",
    "plt.title(f\"Training and Testing MSE (Best Params: reg_param={reg_param}, momentum={momentum}, batch_size={batch_size})\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display the best parameters and loss\n",
    "best_params, best_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a7294",
   "metadata": {},
   "source": [
    "Q2- (30 points) Given the information below, use Naïve Bayes to determine whether File 6 belongs to class label \"Spam\" or \"Ham\" given its features. Answering following questions clearly and accurately. Provide your computational work. \n",
    "---\n",
    "\n",
    "\n",
    "![Generated Dataset](tbl1.jpg)\n",
    "\n",
    "\n",
    "- What are the prior probabilities P(Spam), P(Ham)?\n",
    "\n",
    "    P(Spam) = 2/5 or 40%, P(Ham) = 3/5 or 60%\n",
    "\n",
    "- Compute the required conditional probabilitues corresponding to the parameters of the model by filling the table below.\n",
    "\n",
    "\n",
    "![Generated Dataset](tbl2.png)\n",
    "\n",
    "\n",
    "- What is the probability of File 6 being a Spam? What is the probability of File 6 being a Ham? What can you conclude about the category of File 6? Justify your answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1cf2a-d68a-4f1a-9072-ca4703ce6f76",
   "metadata": {},
   "source": [
    "We will use naive bayes to calculate this:\n",
    "\n",
    "Probability of being spam:\n",
    "$$\n",
    "  P(Spam | Price, Tax, Free) = \\frac{P(Price, Tax, Free | Spam) * P(S)}{P(Price, Tax, Free)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  P(Spam | Price, Tax, Free) = \\frac{ 0.5 * 0.5 * 0.5 * 0.4}{P(Price, Tax, Free)}\n",
    "$$\n",
    "$$\n",
    "  P(Spam | Price, Tax, Free) = \\frac{ 0.05 }{P(Price, Tax, Free)}\n",
    "$$\n",
    "$$\n",
    "  P(Spam | Price, Tax, Free)    \\alpha   0.05 \n",
    "$$\n",
    "\n",
    "Probability of being ham:\n",
    "$$\n",
    "  P(Ham | Price, Tax, Free) = \\frac{P(Price, Tax, Free | Ham) * P(H)}{P(Price, Tax, Free)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  P(Ham | Price, Tax, Free) = \\frac{ 1 * 2/3 * 1/3 * 0.6}{P(Price, Tax, Free)}\n",
    "$$\n",
    "$$\n",
    "  P(Ham | Price, Tax, Free) = \\frac{ 0.1333}{P(Price, Tax, Free)}\n",
    "$$\n",
    "$$\n",
    "  P(Ham | Price, Tax, Free)   \\alpha    0.1333\n",
    "$$\n",
    "\n",
    "Normalizing those results, we'd get ~ \n",
    "\n",
    "$P(Spam | Price, Tax, Free) = \\frac{0.05}{0.05 + 0.1333} = 0.273$\n",
    "\n",
    "$ P(Ham | Price, Tax, Free) = \\frac{0.1333}{0.05 + 0.1333} = 0.727$\n",
    "\n",
    "So, the message is more likely to be ham.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716ef5d",
   "metadata": {},
   "source": [
    "Q3- (6 points) A patient with a positive test wants to know how probable it is to have flu. Find the probability given the information below and provide your computational work. \n",
    "Prior probability: P(not flu)=0.15\n",
    "Likelihood: P(positive│ flu)=0.85\n",
    "Evidence: P(negative)=0.25\n",
    "---\n",
    "From Bayes Theorem:\n",
    "$$\n",
    "P(flu | positive) = \\frac{P (positive | flu) * P(flu)}{P(positive)}\n",
    "$$\n",
    "From basic probability, we konw that $P(flu) = 1 - P(not flu) = 1 - 0.15 = 0.85$ and $P(positive) = 1 - P(negative) = 1 - 0.25 = 0.75$\n",
    "\n",
    "Then, plugging those values in:\n",
    "$$\n",
    "P(flu | positive) = \\frac{0.85 * 0.85}{0.75} = 0.96333...\n",
    "$$\n",
    "\n",
    "Giving us a 96.33% change of having flu... rip.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c8314",
   "metadata": {},
   "source": [
    "Q4- (8 points) Imagine you are tasked with developing a binary classification model to classify emails as either \"spam\" or \"not spam\" based on their content. The observations in the dataset cover several aspects listed in the following table: \n",
    "---\n",
    "\n",
    "\n",
    "![Generated Dataset](tbl3.jpg)\n",
    "\n",
    "You have two different approaches in mind: Naive Bayes classification and Bayesian networks. Answer the following question in the context of this email classification (as “spam” or “not spam”): \n",
    "Discuss the assumptions in Naïve Bayes and Bayesian Network algorithms, as well as advantages and disadvantages of using Naïve Bayes and Bayesian Network classification. Your answer should address the following points: \n",
    "-\tWhat aspects of the problem make Naïve Bayes classification suitable or unsuitable? \n",
    "-\tSimilarly, analyze the suitability of using Bayesian networks for the email classification problem and indicate what unique characteristics of Bayesian networks make them a potentially good or bad choice for this task? \n",
    "-\tDiscuss these methods in terms of their computational efficiency and classification accuracy, considering the features listed in the above table. \n",
    "Include your answer in a table with the following layout:\n",
    "\n",
    "\n",
    "![Generated Dataset](tbl4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5505484",
   "metadata": {},
   "source": [
    "Q5- (6 points) Given the following probability table, build a Naïve Bayes classifier using the Discriminant function. Can this classifier accurately predict if a patient is healthy/not-healthy based on the Test results? (e.g., can a positive test result indicate with high confidence that a patient has flu? How about a negative test result?) Show your mathematical work with proper explanation. Please note that P(Healthy) = 0.25. \n",
    "---\n",
    "![Generated Dataset](tbl5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f02c0-fa5d-4c79-809b-628562916a46",
   "metadata": {},
   "source": [
    "P(Has-Flu) = 1 - P(Healthy) = 1 - 0.25 = 0.75\n",
    "\n",
    "P(Positive | Has-Flu) = 0.8\n",
    "\n",
    "P(Negative | Has-Flu) = 0.2\n",
    "\n",
    "P(Positive | Healthy) = 0.1\n",
    "\n",
    "P(Negative | Healthy) = 0.9\n",
    "\n",
    "\n",
    "\n",
    "Discriminant Function for Positive Test Result: \n",
    "$log \\frac{P(Positive | Has-Flu) * P(Has-Flu)}{P(Positive | Healthy) * P(Healthy)}$\n",
    "\n",
    "$ = log(\\frac{0.8 * 0.75}{0.1 * 0.25}) = 1.38$\n",
    "\n",
    "Discriminant function is *positive*, so the result is mostly likely in class 1, or the \"Has-Flu\" class.\n",
    "\n",
    "\n",
    "Discriminant Function for Negative Test Result: \n",
    "$log \\frac{P(Negative | Has-Flu) * P(Has-Flu)}{P(Negative | Healthy) * P(Healthy)}$\n",
    "\n",
    "$ = log(\\frac{0.2 * 0.75}{0.9 * 0.25}) = -0.176$\n",
    "\n",
    "Discriminant function is *negative*, but not by as much as the first--  so the result is slightly more likely to be in class 2, or the \"healthy\" class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127590e",
   "metadata": {},
   "source": [
    "Q6-(Optional Question- 8 extra points based on the completeness of the answer) Based on the optional document \"Lec12-MultivariateDistributions.pdf\", describe how conditional probabilities are computed in training a Bayesian Network model when the random variables are continuous. Provide an example. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f4a00-c7ac-4dbb-bca0-12c8f3d61740",
   "metadata": {},
   "source": [
    "When the random variables are continuous, you would use a probability density function (PDF) rather than discrete probabilities, for which we can assume a Gaussian distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
